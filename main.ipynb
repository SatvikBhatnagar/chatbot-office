{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313f3f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /home/stoner69/anaconda3/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/stoner69/anaconda3/lib/python3.11/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/stoner69/anaconda3/lib/python3.11/site-packages (from openai==0.28) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /home/stoner69/anaconda3/lib/python3.11/site-packages (from openai==0.28) (3.8.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/stoner69/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/stoner69/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/stoner69/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/stoner69/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/stoner69/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/stoner69/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/stoner69/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/stoner69/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/stoner69/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/stoner69/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install os\n",
    "!pip3 install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e21becee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e7ba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['API_KEY'] = \"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\"\n",
    "openai.api_key = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db4b969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = openai.Completion.create(\n",
    "#     engine=\"text-davinci-002\",\n",
    "#     prompt = 'There was once a',\n",
    "#     max_tokens=50\n",
    "# )\n",
    "# # print(response) -- returns an object\n",
    "# print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f12cf308",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What are the opening hours of the office?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a965266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = openai.ChatCompletion.create(\n",
    "#     model=\"gpt-3.5-turbo-1106\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#         {\"role\": \"user\", \"content\": prompt}\n",
    "#     ],\n",
    "#     max_tokens=50,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3149ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Model:\", response.model)\n",
    "# print(\"Created:\", response.created)\n",
    "# print(\"ID:\", response.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c22eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89503138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#     {'role': 'system', 'content': \"You are a helpful assistant that speaks in Shakespearian language.\"},\n",
    "#     {'role': 'user', 'content': 'What is vertical integration?'}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c4010c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = openai.ChatCompletion.create(\n",
    "#     model = 'gpt-3.5-turbo-1106',    \n",
    "#     messages = messages\n",
    "# )\n",
    "# print(response.choices[0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5ee7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\" : \"system\",\n",
    "        \"content\" :\n",
    "                    \"Welcome to WebDev Solutions Pvt. Ltd.! \\n\"\n",
    "                \"As an assistant for our IT company, I have extensive knowledge\\n\"\n",
    "                \"in web development services, technologies, and best practices.\"\n",
    "                \"Feel free to ask me about website design, development frameworks,\\n\"\n",
    "                \"or any questions related to web development. I'm here to help you\\n\"\n",
    "                \"create impactful and scalable web solutions.\"\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\" :  \"Hello! I'm interested in exploring web development services for my business. Can you\\n\"\n",
    "                     \"provide information about your expertise and the process of building a custom website?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c071c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo-1106',\n",
    "    messages = messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70b0dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"role\" : 'assistant',\n",
    "    \"content\" : response['choices'][0]['message']['content']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7419281",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"role\" : \"user\",\n",
    "    \"content\" : \"I'm looking for a modern and user-friendly website with robust e-commerce capabilities.\\n\"\n",
    "                \"What technologies do you typically use, and what is the usual timeline for developing such a website?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1058c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo-1106',\n",
    "    messages = messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f28c5ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For modern and user-friendly websites with robust e-commerce capabilities, we typically utilize a combination of front-end and back-end technologies to create a responsive, secure, and efficient solution. Here are the key technologies we commonly use for such projects:\n",
      "\n",
      "Front-end Technologies:\n",
      "- HTML5, CSS3, and JavaScript (including modern frameworks like React or Angular) for creating dynamic and interactive user interfaces.\n",
      "- Responsive web design to ensure a seamless experience across various devices and screen sizes.\n",
      "\n",
      "Back-end Technologies:\n",
      "- PHP, Node.js, or other server-side languages for handling data and business logic.\n",
      "- Database technologies such as MySQL or MongoDB to store and retrieve e-commerce-related data.\n",
      "- Integration with e-commerce platforms and payment gateways for transactional functionality.\n",
      "\n",
      "E-commerce Capabilities:\n",
      "- Implementation of robust e-commerce platforms like WooCommerce, Shopify, Magento, or custom-built solutions.\n",
      "- Integration with payment gateways (e.g., PayPal, Stripe, etc.) to facilitate secure online transactions.\n",
      "\n",
      "As for the timeline, the development of a modern and user-friendly website with robust e-commerce capabilities can vary based on the complexity and specific requirements of the project. However, a typical timeline for such a website would include the following stages:\n",
      "\n",
      "- Discovery and Planning: 1-2 weeks\n",
      "- Design: 2-4 weeks\n",
      "- Development: 8-12 weeks\n",
      "- Testing and Quality Assurance: 2-4 weeks\n",
      "- Deployment: 1-2 weeks\n",
      "\n",
      "The timeline may be adjusted based on factors such as the scope of the project, the availability of content and resources, and the feedback and approval process. Additionally, if you have specific deadlines or constraints, we can work to accommodate those as well.\n",
      "\n",
      "If you have any other questions or if there are specific features you're interested in, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6947475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Temperature: \n",
      " For building a modern and user-friendly website with robust e-commerce capabilities, we typically leverage a combination of front-end and back-end technologies to ensure an optimal user experience and efficient e-commerce functionality. Here are some technologies that we commonly use for these types of projects:\n",
      "\n",
      "Front-End Technologies:\n",
      "- HTML5\n",
      "- CSS3 (often with pre-processors such as SASS or LESS)\n",
      "- JavaScript (including popular libraries and frameworks such as React, Vue.js, or Angular)\n",
      "\n",
      "Back-End Technologies:\n",
      "- PHP or Node.js for server-side processing\n",
      "- MySQL, MongoDB, or other databases for data storage\n",
      "- E-commerce platforms such as WooCommerce, Shopify, Magento, or custom e-commerce solutions\n",
      "\n",
      "Additional Tools and Technologies:\n",
      "- Responsive web design frameworks (like Bootstrap or Foundation) for ensuring the site looks great on various devices\n",
      "- Payment gateways integration (such as PayPal, Stripe, or others)\n",
      "- Content management systems (WordPress, Joomla, or custom CMS solutions)\n",
      "\n",
      "As for the timeline, the development of a modern e-commerce website can vary based on factors such as project complexity, feature requirements, and client feedback loops. However, for a standard e-commerce website with robust features, our typical timeline might span from 2-5 months, including design, development, testing, and launch phases. This timeline can be shortened or extended based on your specific needs and the customized functionalities desired for the website.\n",
      "\n",
      "Always discuss timeline-specific requirements during the discovery phase, and we can provide a more accurate estimation of the development timeline based on your project's unique considerations. If you have further inquiries about the technologies we implemented, or more details needed about the timeline specifically, feel free to ask for guidance!\n",
      "\n",
      " \n",
      " \n",
      "\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for gpt-3.5-turbo-1106 in organization org-Q5XiSzEGEZOLXGmbkeVfn9xL on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Enhance response precision and focus by using a lower temperature\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     14\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo-1106\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m     messages \u001b[38;5;241m=\u001b[39m messages,\n\u001b[1;32m     16\u001b[0m     temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     17\u001b[0m     max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLow Temperature: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    702\u001b[0m             result\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for gpt-3.5-turbo-1106 in organization org-Q5XiSzEGEZOLXGmbkeVfn9xL on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing."
     ]
    }
   ],
   "source": [
    "# Increase response creativity and diversity with higher temperature\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo-1106',\n",
    "    messages = messages,\n",
    "    temperature = 1.6,\n",
    "    max_tokens = 400\n",
    ")\n",
    "print(\"High Temperature: \\n\", response.choices[0]['message']['content'])\n",
    "\n",
    "print(\"\\n \\n \\n\")\n",
    "\n",
    "# Enhance response precision and focus by using a lower temperature\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo-1106',\n",
    "    messages = messages,\n",
    "    temperature = 0,\n",
    "    max_tokens = 400\n",
    ")\n",
    "print(\"Low Temperature: \\n\", response.choices[0]['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
